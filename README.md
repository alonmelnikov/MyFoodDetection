# MyFoodDetection

A Flutter food detection application that uses Google Cloud Vision API to identify food items and display their nutritional information.

## Features

- ğŸ“¸ **Camera Integration**: Capture food images directly from your device
- ğŸ¤– **AI-Powered Detection**: Uses Google Cloud Vision API to identify food items
- ğŸ“Š **Food History**: View your previously captured food items
- ğŸ¨ **Clean Architecture**: Organized with data models, services, and UI layers
- âš¡ **Riverpod State Management**: Efficient and reactive state management
- ğŸ” **Debug Logging**: Comprehensive logging for easy debugging

## Architecture

The app follows clean architecture principles:

- **Models**: Data structures (`FoodItem`, `FoodDetectionResult`, `Result<T,E>`)
- **Services**: 
  - `FoodDetectionService`: Handles image analysis via Cloud Run endpoint
  - `ApiService`: Generic HTTP client with error handling
- **Data Models**: Business logic layer (`FoodHistoryDataModel`)
- **UI**: Stateless screens powered by Riverpod (`FoodHistoryScreen`)

## Tech Stack

- **Flutter** - Cross-platform mobile framework
- **Riverpod** - State management
- **Google Cloud Vision** - Food detection AI
- **HTTP** - API communication
- **Image Picker** - Camera integration

## Getting Started

### Prerequisites

- Flutter SDK (latest stable version)
- Xcode (for iOS development)
- Android Studio (for Android development)
- Google Cloud Vision API endpoint

### Installation

1. Clone the repository:
```bash
git clone https://github.com/alonmelnikov/MyFoodDetection.git
cd MyFoodDetection
```

2. Install dependencies:
```bash
flutter pub get
```

3. Run the app:
```bash
flutter run
```

## Project Structure

```
lib/
â”œâ”€â”€ dataModels/          # Business logic & state management
â”‚   â”œâ”€â”€ food_history_data_model.dart
â”‚   â”œâ”€â”€ food_history_notifier.dart
â”‚   â””â”€â”€ food_history_state.dart
â”œâ”€â”€ enums/               # Enumerations
â”‚   â””â”€â”€ network_errors.dart
â”œâ”€â”€ models/              # Data models
â”‚   â”œâ”€â”€ food_detection_result.dart
â”‚   â”œâ”€â”€ food_item.dart
â”‚   â””â”€â”€ result.dart
â”œâ”€â”€ services/            # API & external services
â”‚   â”œâ”€â”€ api_service.dart
â”‚   â””â”€â”€ food_detection_service.dart
â”œâ”€â”€ ui/                  # User interface
â”‚   â””â”€â”€ screens/
â”‚       â””â”€â”€ food_history_screen.dart
â””â”€â”€ main.dart            # App entry point
```

## How It Works

1. User taps "Capture Food" button
2. Camera opens to capture image
3. Image is sent to Google Cloud Vision endpoint
4. AI detects food label and confidence
5. Result is displayed in the history list
6. All steps are logged for debugging

## Debug Logs

The app includes comprehensive logging at each layer:
- `[FoodDetection]` - Detection service logs
- `[DataModel]` - Business logic logs  
- `[CaptureFood]` - UI/state management logs

## Future Enhancements

- [ ] Add nutrition database integration (USDA FoodData Central)
- [ ] Implement local persistence (Hive/SharedPreferences)
- [ ] Add macro tracking (calories, carbs, protein, fat)
- [ ] Food item editing capabilities
- [ ] Export history as CSV/JSON

## License

This project is open source and available under the MIT License.

## Author

**Alon Melnikov**
- GitHub: [@alonmelnikov](https://github.com/alonmelnikov)
